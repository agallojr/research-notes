
-- So it begins...  --

After some months, perhaps more than a year, we've been tracking the quantum computing space with increasing interest.  Prior to that it was the stuff of science fiction, more recently more akin to cold fusion - we'll believe it when we see it, maybe someday in the far distant future it will be useful for something.

Quantum is clearly still in its infancy.  I had dinner with a PhD physicist at SC23 and he admitted the best medium-term application of quantum computing is to model quantum systems.  Because otherwise, if there are applications of interest besides cryptography, we don't know about them as most people have no idea how to program these things.  

And on first blush, they are entirely foreign.  Not like OO was to procedural.  A real mind f***.  We can sit in 10 hours of online tutorials on quantum and still never write "hello world", add two numbers.  

To compound matters, the base physics which is used to build these non-von Neumann machines varies.  For example, Xanadu.ai funds and supports two open source libraries, depending on the underlying physics of the machine.  Some are gate-based, some are not.

Walled gardens are already springing up in this greenfield.  Most notably NVIDIA.  While cuQuantum promises to bring performant quantum simulation to enterprise NVIDIA customers, those unable to buy a DGX are shut out (or sent to the cloud).  And while NVIDIA promotes heterogeneous architectures (e.g. Grace Hopper), they seem primarily concerned with heterogeneity in the context of their own product line.  Heterogeneous systems will likely be the norm in the quantum space - CPUs, GPUs, QPUs, and so on.  Within these classes of chips, we have chiplets.  Clearly the enterprise must be concerned with managing heterogeneity in their codebase which often contains critical IP.  

The choice of language itself must be made, again, as it was with HPC and GPUs.  Here Python does seem to have an early lead over C++, but there are lower assembly standards, and given the variation in the hardware physics, standards which can still take 100% most performant use of the hardware will likely take a while to emerge, and until then arguments with those who put performance first will be necessary.

Enterprises should prepare for an unmaintainable debris field from their scientific and engineering programmers in both the LLM and quantum spaces, and given its more maturity and alignment with current software practices, the debris field in LLM extends and blooms for business apps too (apps, and models, including personal ones... an operational nightmare for teams not ready to deal).

As in GPUs with CUDA and more portable abstractions like SYCL, IBM, ironically to the senior staff, leads the way in support of open standards.  Qiskit is the top platform for quantum today in terms of installed base, and it promises to support hardware other than just IBM's.  We also see frameworks putting Qiskit under the hood, supporting a "driver for Qiskit".

Qiskit quantum simulations can run on commodity hardware up to a small number of qubits, but enough to get started.  We're also interested in PennyLane supported by Xanadu, but it does more than just support programming gates, and we're not prepared to take on that.  

Hardware, and support in simulators, will limit what can be done.  For example, not only are total qubits limited to maybe a dozen or two, in many cases 3-qubit gates are not yet supported by the simulators.

So for the moment we'll play with Qiskit and see what happens, then perhaps try the similar-to with PennyLane and gates, and then get into the stuffier stuff, and some of the potential applications.


-- Qiskit -- 

Quantum seems to be in a similar situation as the LLMs... the documentation stinks, examples don't work, etc.  After a few googles, RTFMs, and various failed attempted, I did get a basic null circuit working on the IBM simulator.  A login is required on the IBM site, even if the local simulator is used (not too cool).  In theory every new user gets some IBM cloud credits, so we should be able to run the example up there too, but we'll wait for now.  

On run of a working circuit, we see this:

(qiskit) {develop} ~/src/research-notes/src/qiskit $ python hello_world_1.py 
/home/agallojr/src/research-notes/src/qiskit/hello_world_1.py:14: DeprecationWarning: Circuits that do not match the target hardware definition will no longer be supported after March 1, 2024. See the transpilation documentation (https://docs.quantum.ibm.com/transpile) for instructions to transform circuits and the primitive examples (https://docs.quantum.ibm.com/run/primitives-examples) to see this coupled with operator transformations.
  job = Sampler(backend).run(qc)
job id: cnbps1nmo951g805let0
SamplerResult(quasi_dists=[{0: 1.0}], metadata=[{'shots': 4000, 'circuit_metadata': {}}])

That's like a week from now.  The complaint seems to be with this:

    job = Sampler(backend).run(qc)

We'll look into the evolving signatures and try to stay with the tip.


-- Alternative simulators, alternate SDKs - PennyLane -- 

Aer is a simulator, similar to the IBM QASM.  The latter requires an IBM login, the former does not (though it seems to create a null IBM config file anyway? cuz Qiskit?).  Aer package itself contains more than one simulator, for different noise profiles, etc.  We'll have to look into the differences at some point.

Transpiling can be used to target the circuit on a specific simulator, pre-chew it for performance.  Not surprising, GPU support on Windows Linux (WSL) is not supported at least with my commodity GPU.

PennyLane is a competitor to Qiskit, and supports a plugin for Qiskit, thus permitting one to use PennyLane vs. IBM simulators and hardware.  Config files are used to specify the hardware device.  Qiskit code can be imported wholely and used with PennyLane-managed devices and gradient algorithms.  Compilation of circuits for specific platforms with Catalyst is also possible.

The Canadian government has just given parent firm Xanadu a cash influx to aid in dissemination and adoption of the technology.  This is based in southern Ontario.  (D-Wave is also based in Canada.) Upfront Xanadu claims the goal is to democratize.  First contact with their installation instructions was a good experience, examples worked relatively painlessly.

We've now written a basic circuit and using PennyLane we've run it on a variety of simulators and real machines at AWS and IBM.  And it was remarkably easy.  Tho we notice that in both cloud cases the local Python process idled while the remote process was in queue and then running.  Clearly there needs to be / is some kind of batch submission idiom to investigate.  Its also remarkable (of course) that the cloud providers match our lwfm model of sites and compute types.

Also clearly we need to know more about leveraging a quantum step in a broader "hybrid" computation or workflow.  


-- Problem morphing into quantum forms --

Taking a problem and morphing it into a circuit is a problem.  It reminds of proving a problem is NP Complete.  (Insert horror story from grad school algorithms class here.)  In theory, given LLM planning abilities, an LLM should be helpful in problem transformation.  Also, in gate based quantum models, the set of verbs is small, thus the potential for a coding assistant which implements the transformed problem seems plausible.  We will look into that.

But circuits are not the only computing paradigm (pulse photon, quantum neuromorphic, adiabatic / annealing, etc.) and the algorithms are sensitive to or even dependent upon the underlying physics.  e.g. a brain-inspired universal quantum perceptron is emergent, as yet to be agreeably specified.  QASM is a good place to start, but will also likely come under pressure from the variation in emerging hardware.  Much work is being done with the researcher only running on a simulator, as the real machine isn't yet realized, simply to better understand the range of the possible (e.g. divide and conquer as applied to quantum algorithms).  There's even some back-and-forth such as using quantum computing to understand quantum state physics, and using quantum state physics to understand quantum computing.








